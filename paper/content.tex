\input{introduction}

\section{Related work}

BRL and SBRL

	Recent work in the field of decision lists has focused on the creation of probabilistic decision lists that generate a posterior distribution over the space of potential decision lists\citep{LethamRuMcMa15,YangRuSe16}. These methods achieve good accuracy while maintaining a small execution time. In addition, these methods improve on existing methods such as CART or C5.0 by optimizing over the global space of decision lists as opposed to searching for rules greedily and getting stuck at local optima. We take the same approach towards optimizing over the global search space, though we donâ€™t use probabilistic techniques. In addition, we use the rule mining framework from \citep{LethamRuMcMa15} to generate the rules for our data sets. \citep{YangRuSe16} builds on \citep{LethamRuMcMa15} by placing bounds on the search space and creating a high performance bit vector manipulation library. We use that bit vector manipulation library to perform our computations, and add additional bounds to further prune the search space.

Garofalakis

Efficient Algorithms for Constructing Decision Trees with Constraints, Scalable Data Mining with Model Constraints, Building Decision Trees with Constraints

	Our use of a branch and bound technique has also been applied to decision tree generation methods. \citep{garofalakis:2000-kdd} created an algorithm to generate more interpretable decision trees by allowing one to constrain the size of the decision tree. \citep{garofalakis:2000-kdd} uses branch-and-bound to constrain the size of the search space and limit the eventual size of the decision tree. During tree construction, \citep{garofalakis:2000-kdd} bounds the possible MDL cost of every different split at a given node. If every split at that node is more expensive than the actual cost of the current subtree, then that node can be pruned. In this way, they were able to prune the tree while constructing it instead of just constructing the tree and then pruning at the end.

ProPublica

	Certain problems require that the model used to solve that problem be interpretable as well as accurate. \citep{LarsonMaKiAn16} examines the problem of predicting recidivism and shows that a black box model, specifically the COMPAS score from the company Northpointe, has racially biased prediction. Black defendants are misclassified at a higher risk for recidivism than in actuality, while white defendants are misclassified at a lower risk. The model which produces the COMPAS scores is a black box algorithm which is not interpretable, and therefore the model does not provide a way for human input to correct for these racial biases. Our model produces similar accuracies to the logistic regression and COMPAS scores from \citep{LarsonMaKiAn16} while maintaining its interpretability.

\citep{rivest:1987}

\citep{LethamRuMcMa15}

\citep{YangRuSe16}

\citep{garofalakis:2000-kdd,garofalakis:2000-sigkdd,garofalakis:2003}

\input{framework}

\input{bounds}

\section{Implementation architecture}

We present an architecture for executing our branch-and-bound algorithm,
consisting of a cache, a queue that is associated with a search policy,
and, optionally, a symmetry-aware map.
%
First, we describe the cache, our primary data structure~(\S\ref{sec:cache});
it is organized as a prefix tree and supports the incremental computations,
detailed in~\S\ref{sec:incremental}, that are central to our approach.
%
Second, we describe the queue and search policy~(\S\ref{sec:queue}).
%
Like the queue in Algorithm~\ref{alg:branch-and-bound},
our queue keeps track of which prefixes to evaluate during execution.
%
The policy for selecting a prefix from the queue to evaluate next,
and thus also the natural queue data structure, depend on
the search policy employed for exploring the space of rule lists
%
Next, we describe the symmetry-aware map~(\S\ref{sec:map}),
which enables garbage collection of prefixes eliminated by the
equivalent support bound in Theorem~\ref{sec:equivalent}.
%
While we present the map as an optional component of our architecture,
our calculations in~\S\ref{sec:permutation-counting}
and experiments in~\S\ref{sec:experiments} demonstrate that
it is critical for efficient and practical algorithm performance.
%
Finally, we summarize an artifact we implemented~(\S\ref{sec:system}),
which we evaluate in~\S\ref{sec:experiments}.

\subsection{Prefix tree cache for incremental computation}
\label{sec:cache}

We maintain a cache to support incremental computation.
%
Our cache is organized as a prefix tree, which is also known as a trie.
%

\subsection{Queue and search policies}
\label{sec:queue}

Different search policies suggest different natural queue data structures.

\begin{itemize}
\item breadth-first
\item depth-first
\item something based on greedy
\item (curiosity, lower bound, optimization) $\times$ (priority queue, something like Thompson sampling)
\item optimistic
\end{itemize}

\subsection{Map data structure for symmetry-aware garbage collection}
\label{sec:map}

%\subsection{Large-scale optimization}

\subsection{System}
\label{sec:system}

\section{Preliminary experiments}
\label{sec:experiments}

Notes:
\begin{itemize}

\item Measurements over multiple executions (corresponding to ten folds)
should include standard deviations

\item Most figures will be generated with one particular big dataset
\end{itemize}

Probably want to integrate some measurements of the permutation map's effects
(from Margo's email):
\begin{itemize}
\item How many times do we look up an item in the hash map that is not in the tree?

\item When we do look up an item, how many times do we end up discarding
      something we would have been unable to discard had we not done this.

\item How is the hash map growing over time?

\item How is the tree growing over time?
\end{itemize}

Figures:
\begin{itemize}

\item Figure~\ref{fig:comparison}, Comparison with other methods:
Test error for us and a few other algorithms
(CART, C4.5, CBA, CMAR/CPAR, C5.0, Ripper, \dots),
as a function of sparsity (number of rules) over 10 folds, for one big dataset (box plots).
Also report algorithm runtimes (mean $\pm$ standard deviation over 10 folds).
Also compare accuracies to random forests and boosted decision trees.

\item Figure~\ref{fig:regularization}
Missing:  Test error as a function of regularization and sparsity
(number of rules) as a function of regularization, over 10 folds,
for one big dataset.

\item Figure~\ref{fig:ablation},  Ablation experiment:
Show the effect of each ``piece'' at a time,
run X without each in turn and show the difference in either
quality of solution or runtime or amount of memory, size of cache or queue,
where X is a specific implementation
(meaning a specific scheduling policy and node type)

\item Figure~\ref{fig:scheduling-policy}
Missing:  Some sort of comparison of different scheduling policies

\item Figure~\ref{fig:queue-cache-size-insertions} (top),
Size of cache and queue data structures as a function of wall clock time

\item Figure~\ref{fig:queue-cache-size-insertions} (bottom),
Cumulative number of things placed in queue over time

\item Figure~\ref{fig:objective}, Objective value over time,
with horizontal lines and x-ticks for CART and C4.5
%-- this also gives an upper bound on the remaining search space --
%and also, possibly, the minimum lower bound in the queue over time

\item Figure~\ref{fig:search-space},
Fraction of search space we've proven we've handled

\item Figure~\ref{fig:max-length},
Max prefix length over time (computed from objective value);

\item Figure~\ref{fig:prefix-length},
Best prefix length over time

\item Some characterization of the number of solutions close to optimal
(plot number of suboptimal solutions vs amount of suboptimality,
removing permutations)

\item Some example rule lists to show how interpretable they are.
Potentially we could display equally optimal rule lists that look
very different from each other.

\end{itemize}

\section{Conclusions}

\subsubsection*{Acknowledgments}

E.A. is supported by the Miller Institute for Basic Research in Science,
University of California, Berkeley.

\bibliography{refs}
\bibliographystyle{abbrvnat}

\begin{figure}[t!]
\begin{center}
%\includegraphics[width=0.75\textwidth]{figs/sketch-comparison.png}
\includegraphics[width=0.75\textwidth]{figs/compare-compas.pdf}
\end{center}
\caption{Comparison with other methods:
Test error for us and a few other algorithms
(CART, C4.5, CBA, CMAR/CPAR, C5.0, Ripper, \dots),
as a function of sparsity over 10 folds, for one big dataset (box plots).
Also report algorithm runtimes (mean $\pm$ standard deviation over 10 folds).}
\label{fig:comparison}
\end{figure}

\begin{figure}[t!]
\begin{center}
\end{center}
\caption{Missing:  Test error as a function of regularization and sparsity
(number of rules) as a function of regularization, over 10 folds,
for one big dataset.}
\label{fig:regularization}
\end{figure}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.75\textwidth]{figs/sketch-ablation.png}
\end{center}
\caption{Ablation experiment:
Show the effect of each ``piece'' at a time,
run X without each in turn and show the difference in either
quality of solution or runtime or amount of memory, size of cache or queue,
where X is a specific implementation
(meaning a specific scheduling policy and node type)}
\label{fig:ablation}
\end{figure}

\begin{figure}[t!]
\begin{center}
\end{center}
\caption{Missing:  Some sort of comparison of different scheduling policies}
\label{fig:scheduling-policy}
\end{figure}

\begin{figure}[t!]
\begin{center}
%\includegraphics[width=0.65\textwidth]{figs/sketch-queue-size.png}
\includegraphics[width=0.8\textwidth]{figs/ela_compas-queue-cache-size-insertions.pdf}
\end{center}
\caption{Cache and queue data structure sizes and insertions.
%
The top plot shows the sizes of the cache and queue data structures,
as a function of wall clock time.
%
The number of nodes in the cache (solid black line) is an
upper bound on the number of elements in the physical queue
(dotted gray line), since the physical queue elements only
correspond to the cache trie data structure's leaf nodes
plus disconnected cache nodes that have been marked for deletion.
%
The queue's physical size is an upper bound on its
logical size (solid blue line), which doesn't include nodes
that have been marked for deletion.
%
The bottom plot shows the cumulative number of cache insertions,
which is equivalent to the cumulative number of queue insertions,
as a function of wall clock time.
}
\label{fig:queue-cache-size-insertions}
\end{figure}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{figs/ela_compas-queue.pdf}
\end{center}
\caption{Logical queue composition.
}
\label{fig:queue}
\end{figure}

\begin{figure}[t!]
\begin{center}
%\includegraphics[width=0.65\textwidth]{figs/sketch-objective.png}
\includegraphics[width=0.8\textwidth]{figs/ela_compas-objective.pdf}
\end{center}
\caption{Objective value as a function of wall clock time.
%
The top plot shows the entire execution, and the bottom plot
highlights the optimization phase, from the start of execution
to the time at which the optimal value is achieved.
%
The cyan circle indicates the objective value after a single iteration,
and the magenta square indicates the time at which the optimum
is achieved, as well as its value.
%
Missing: horizontal lines and x-ticks for CART and C4.5.}
\label{fig:objective}
\end{figure}

\begin{figure}[t!]
\begin{center}
%\includegraphics[width=0.65\textwidth]{figs/sketch-search-space.png}
\includegraphics[width=0.8\textwidth]{figs/ela_compas-remaining-space.pdf}
\end{center}
\caption{The logarithm (base 10) of an upper bound
on the size of the remaining search space,
as a function of wall clock time.
%
These plots show the upper bound in
Proposition~\ref{prop:remaining-eval-coarse},
which depends on the total number of available rules,
as well as two dynamic quantities:
the current best objective value,
and the histogram of logical queue elements,
partitioned by prefix length.
%
The top plot shows the entire execution,
the middle plot highlights the optimization phase,
and the bottom plot highlights the verification phase.}
\label{fig:search-space}
\end{figure}

%\begin{figure}[t!]
%\begin{center}
%%\includegraphics[width=0.65\textwidth]{figs/sketch-max-length.png}
%\includegraphics[width=0.8\textwidth]{figs/ela-max-length-check.png}
%\end{center}
%\caption{Max prefix length over time (computed from objective value)}
%\label{fig:max-length}
%\end{figure}
%
\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{figs/ela_compas-prefix-length.pdf}
\end{center}
\caption{Best prefix length over time}
\label{fig:prefix-length}
\end{figure}
