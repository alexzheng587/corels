\input{introduction}

\input{related_work}

\citep{rivest:1987}

\citep{LethamRuMcMa15}

\citep{YangRuSe16}

\citep{garofalakis:2000-kdd,garofalakis:2000-sigkdd,garofalakis:2003}

\input{framework}

\input{bounds}

\section{Implementation architecture}

We present an architecture for executing our branch-and-bound algorithm,
consisting of a cache, a queue that is associated with a search policy,
and, optionally, a symmetry-aware map.
%
First, we describe the cache, our primary data structure~(\S\ref{sec:cache});
it is organized as a prefix tree and supports the incremental computations,
detailed in~\S\ref{sec:incremental}, that are central to our approach.
%
Second, we describe the queue and search policy~(\S\ref{sec:queue}).
%
Like the queue in Algorithm~\ref{alg:branch-and-bound},
our queue keeps track of which prefixes to evaluate during execution.
%
The policy for selecting a prefix from the queue to evaluate next,
and thus also the natural queue data structure, depend on
the search policy employed for exploring the space of rule lists
%
Next, we describe the symmetry-aware map~(\S\ref{sec:map}),
which enables garbage collection of prefixes eliminated by the
equivalent support bound in Theorem~\ref{sec:equivalent}.
%
While we present the map as an optional component of our architecture,
our calculations in~\S\ref{sec:permutation-counting}
and experiments in~\S\ref{sec:experiments} demonstrate that
it is critical for efficient and practical algorithm performance.
%
Finally, we summarize an artifact we implemented~(\S\ref{sec:system}),
which we evaluate in~\S\ref{sec:experiments}.

\subsection{Prefix tree cache for incremental computation}
\label{sec:cache}

We maintain a cache to support incremental computation.
%
Our cache is organized as a prefix tree, which is also known as a trie.
%

\subsection{Queue and search policies}
\label{sec:queue}

Different search policies suggest different natural queue data structures.

\begin{itemize}
\item breadth-first
\item depth-first
\item something based on greedy
\item (curiosity, lower bound, optimization) $\times$ (priority queue, something like Thompson sampling)
\item optimistic
\end{itemize}

\subsection{Map data structure for symmetry-aware garbage collection}
\label{sec:map}

%\subsection{Large-scale optimization}

\subsection{System}
\label{sec:system}

\section{Preliminary experiments}
\label{sec:experiments}

Notes:
\begin{itemize}

\item Measurements over multiple executions (corresponding to ten folds)
should include standard deviations

\item Most figures will be generated with one particular big dataset
\end{itemize}

Probably want to integrate some measurements of the permutation map's effects
(from Margo's email):
\begin{itemize}
\item How many times do we look up an item in the hash map that is not in the tree?

\item When we do look up an item, how many times do we end up discarding
      something we would have been unable to discard had we not done this.

\item How is the hash map growing over time?

\item How is the tree growing over time?
\end{itemize}

Figures:
\begin{itemize}

\item Figure~\ref{fig:comparison}, Comparison with other methods:
Test error for us and a few other algorithms
(CART, C4.5, CBA, CMAR/CPAR, C5.0, Ripper, \dots),
as a function of sparsity (number of rules) over 10 folds, for one big dataset (box plots).
Also report algorithm runtimes (mean $\pm$ standard deviation over 10 folds).
Also compare accuracies to random forests and boosted decision trees.

\item Figure~\ref{fig:regularization}
Missing:  Test error as a function of regularization and sparsity
(number of rules) as a function of regularization, over 10 folds,
for one big dataset.

\item Figure~\ref{fig:ablation},  Ablation experiment:
Show the effect of each ``piece'' at a time,
run X without each in turn and show the difference in either
quality of solution or runtime or amount of memory, size of cache or queue,
where X is a specific implementation
(meaning a specific scheduling policy and node type)

\item Figure~\ref{fig:scheduling-policy}
Missing:  Some sort of comparison of different scheduling policies

\item Figure~\ref{fig:queue-cache-size-insertions} (top),
Size of cache and queue data structures as a function of wall clock time

\item Figure~\ref{fig:queue-cache-size-insertions} (bottom),
Cumulative number of things placed in queue over time

\item Figure~\ref{fig:objective}, Objective value over time,
with horizontal lines and x-ticks for CART and C4.5
%-- this also gives an upper bound on the remaining search space --
%and also, possibly, the minimum lower bound in the queue over time

\item Figure~\ref{fig:search-space},
Fraction of search space we've proven we've handled

\item Figure~\ref{fig:max-length},
Max prefix length over time (computed from objective value);

\item Figure~\ref{fig:prefix-length},
Best prefix length over time

\item Some characterization of the number of solutions close to optimal
(plot number of suboptimal solutions vs amount of suboptimality,
removing permutations)

\item Some example rule lists to show how interpretable they are.
Potentially we could display equally optimal rule lists that look
very different from each other.

\end{itemize}

\section{Conclusions}

\subsubsection*{Acknowledgments}

E.A. is supported by the Miller Institute for Basic Research in Science,
University of California, Berkeley.

\bibliography{refs}
\bibliographystyle{abbrvnat}

\begin{figure}[t!]
\begin{center}
%\includegraphics[width=0.75\textwidth]{figs/sketch-comparison.png}
\includegraphics[width=0.75\textwidth]{figs/compare-compas.pdf}
\end{center}
\caption{Comparison with other methods:
Test error for us and a few other algorithms
(CART, C4.5, CBA, CMAR/CPAR, C5.0, Ripper, \dots),
as a function of sparsity over 10 folds, for one big dataset (box plots).
Also report algorithm runtimes (mean $\pm$ standard deviation over 10 folds).}
\label{fig:comparison}
\end{figure}

\begin{figure}[t!]
\begin{center}
\end{center}
\caption{Missing:  Test error as a function of regularization and sparsity
(number of rules) as a function of regularization, over 10 folds,
for one big dataset.}
\label{fig:regularization}
\end{figure}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.75\textwidth]{figs/sketch-ablation.png}
\end{center}
\caption{Ablation experiment:
Show the effect of each ``piece'' at a time,
run X without each in turn and show the difference in either
quality of solution or runtime or amount of memory, size of cache or queue,
where X is a specific implementation
(meaning a specific scheduling policy and node type)}
\label{fig:ablation}
\end{figure}

\begin{figure}[t!]
\begin{center}
\end{center}
\caption{Missing:  Some sort of comparison of different scheduling policies}
\label{fig:scheduling-policy}
\end{figure}

\begin{figure}[t!]
\begin{center}
%\includegraphics[width=0.65\textwidth]{figs/sketch-queue-size.png}
\includegraphics[width=0.8\textwidth]{figs/ela_compas-queue-cache-size-insertions.pdf}
\end{center}
\caption{Cache and queue data structure sizes and insertions.
%
The top plot shows the sizes of the cache and queue data structures,
as a function of wall clock time.
%
The number of nodes in the cache (solid black line) is an
upper bound on the number of elements in the physical queue
(dotted gray line), since the physical queue elements only
correspond to the cache trie data structure's leaf nodes
plus disconnected cache nodes that have been marked for deletion.
%
The queue's physical size is an upper bound on its
logical size (solid blue line), which doesn't include nodes
that have been marked for deletion.
%
The bottom plot shows the cumulative number of cache insertions,
which is equivalent to the cumulative number of queue insertions,
as a function of wall clock time.
}
\label{fig:queue-cache-size-insertions}
\end{figure}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{figs/ela_compas-queue.pdf}
\end{center}
\caption{Logical queue composition.
}
\label{fig:queue}
\end{figure}

\begin{figure}[t!]
\begin{center}
%\includegraphics[width=0.65\textwidth]{figs/sketch-objective.png}
\includegraphics[width=0.8\textwidth]{figs/ela_compas-objective.pdf}
\end{center}
\caption{Objective value as a function of wall clock time.
%
The top plot shows the entire execution, and the bottom plot
highlights the optimization phase, from the start of execution
to the time at which the optimal value is achieved.
%
The cyan circle indicates the objective value after a single iteration,
and the magenta square indicates the time at which the optimum
is achieved, as well as its value.
%
Missing: horizontal lines and x-ticks for CART and C4.5.}
\label{fig:objective}
\end{figure}

\begin{figure}[t!]
\begin{center}
%\includegraphics[width=0.65\textwidth]{figs/sketch-search-space.png}
\includegraphics[width=0.8\textwidth]{figs/ela_compas-remaining-space.pdf}
\end{center}
\caption{The logarithm (base 10) of an upper bound
on the size of the remaining search space,
as a function of wall clock time.
%
These plots show the upper bound in
Proposition~\ref{prop:remaining-eval-coarse},
which depends on the total number of available rules,
as well as two dynamic quantities:
the current best objective value,
and the histogram of logical queue elements,
partitioned by prefix length.
%
The top plot shows the entire execution,
the middle plot highlights the optimization phase,
and the bottom plot highlights the verification phase.}
\label{fig:search-space}
\end{figure}

%\begin{figure}[t!]
%\begin{center}
%%\includegraphics[width=0.65\textwidth]{figs/sketch-max-length.png}
%\includegraphics[width=0.8\textwidth]{figs/ela-max-length-check.png}
%\end{center}
%\caption{Max prefix length over time (computed from objective value)}
%\label{fig:max-length}
%\end{figure}
%
\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{figs/ela_compas-prefix-length.pdf}
\end{center}
\caption{Best prefix length over time}
\label{fig:prefix-length}
\end{figure}
